{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ejercicio: An√°lisis robusto de segmentaci√≥n de clientes con t√©cnicas no param√©tricas\n",
        "\n",
        "Preparaci√≥n de dataset con caracter√≠sticas no normales:"
      ],
      "metadata": {
        "id": "y_jPWndwXRHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixv9rZ_UXIHN",
        "outputId": "5bfd3fc2-7d7b-439c-c458-35765a125c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET PARA AN√ÅLISIS NO PARAM√âTRICO\n",
            "========================================\n",
            "Clientes analizados: 300\n",
            "Distribuciones generadas:\n",
            "- Gasto total: Exponencial (Distinta media por grupo)\n",
            "- Frecuencia visitas: Poisson (discreta)\n",
            "- Satisfacci√≥n: Beta (acotada 0-10)\n",
            "\n",
            "TEST DE NORMALIDAD (Shapiro-Wilk):\n",
            "----------------------------------------\n",
            "gasto_total          | Normal: NO (p=2.8664e-21)\n",
            "satisfaccion         | Normal: NO (p=5.7815e-07)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "\n",
        "# ==========================================\n",
        "# 1. GENERACI√ìN DE DATOS (NO NORMALES)\n",
        "# ==========================================\n",
        "np.random.seed(42)\n",
        "n_clientes = 300\n",
        "\n",
        "# Definimos segmentos primero\n",
        "segmentos_lista = np.random.choice(['Bronce', 'Plata', 'Oro'], n_clientes, p=[0.5, 0.3, 0.2])\n",
        "\n",
        "# Generamos gasto dependiente del segmento para asegurar diferencias\n",
        "# Usamos distribuci√≥n exponencial (no normal) con diferentes escalas (medias)\n",
        "gasto_data = []\n",
        "for seg in segmentos_lista:\n",
        "    if seg == 'Oro':\n",
        "        val = np.random.exponential(scale=450) # Media 450\n",
        "    elif seg == 'Plata':\n",
        "        val = np.random.exponential(scale=250) # Media 250\n",
        "    else: # Bronce\n",
        "        val = np.random.exponential(scale=150) # Media 150\n",
        "    gasto_data.append(val)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'cliente_id': range(1, n_clientes + 1),\n",
        "    'segmento': segmentos_lista,\n",
        "    'gasto_total': gasto_data,\n",
        "    'frecuencia_visitas': np.random.poisson(3, n_clientes),  # Conteos (Poisson)\n",
        "    'satisfaccion': np.random.beta(5, 2, n_clientes) * 10,   # Beta (asimetr√≠a negativa, alta satisfacci√≥n)\n",
        "    'antiguedad_dias': np.random.exponential(365, n_clientes).astype(int)\n",
        "})\n",
        "\n",
        "print(\"DATASET PARA AN√ÅLISIS NO PARAM√âTRICO\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Clientes analizados: {len(df)}\")\n",
        "print(\"Distribuciones generadas:\")\n",
        "print(\"- Gasto total: Exponencial (Distinta media por grupo)\")\n",
        "print(\"- Frecuencia visitas: Poisson (discreta)\")\n",
        "print(\"- Satisfacci√≥n: Beta (acotada 0-10)\")\n",
        "\n",
        "# Verificar no normalidad (Shapiro-Wilk)\n",
        "print(\"\\nTEST DE NORMALIDAD (Shapiro-Wilk):\")\n",
        "print(\"-\" * 40)\n",
        "# Solo probamos gasto y satisfacci√≥n para no saturar la salida\n",
        "for col in ['gasto_total', 'satisfaccion']:\n",
        "    stat, p = stats.shapiro(df[col])\n",
        "    normal = \"S√ç\" if p > 0.05 else \"NO\"\n",
        "    print(f\"{col:20} | Normal: {normal} (p={p:.4e})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. COMPARACIONES NO PARAM√âTRICAS\n",
        "# ==========================================\n",
        "\n",
        "# Preparar datos por segmento\n",
        "segmentos_dict = {}\n",
        "orden_segmentos = ['Bronce', 'Plata', 'Oro']\n",
        "for seg in orden_segmentos:\n",
        "    segmentos_dict[seg] = df[df['segmento'] == seg]['gasto_total'].values\n",
        "\n",
        "print(\"\\nCOMPARACI√ìN DE GASTO TOTAL ENTRE SEGMENTOS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Estad√≠sticas descriptivas robustas (Mediana y Rango Intercuartil)\n",
        "print(f\"{'Segmento':10} | {'Mediana':>10} | {'IQR':>10} | {'n':>5}\")\n",
        "print(\"-\" * 45)\n",
        "for seg in orden_segmentos:\n",
        "    datos = segmentos_dict[seg]\n",
        "    mediana = np.median(datos)\n",
        "    q25, q75 = np.percentile(datos, [25, 75])\n",
        "    iqr = q75 - q25\n",
        "    print(f\"{seg:10} | ${mediana:9.0f} | ${iqr:9.0f} | {len(datos):5}\")\n",
        "\n",
        "# Prueba Kruskal-Wallis (ANOVA no param√©trico)\n",
        "# H0: Las medianas de todos los grupos son iguales\n",
        "# Desempaquetamos los valores del diccionario en orden\n",
        "h_stat, p_kw = stats.kruskal(*segmentos_dict.values())\n",
        "\n",
        "print(\"\\nPRUEBA KRUSKAL-WALLIS (Global):\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Estad√≠stico H: {h_stat:.3f}\")\n",
        "print(f\"Valor p: {p_kw:.4e}\") # Notaci√≥n cient√≠fica para p muy peque√±os\n",
        "print(f\"¬øExisten diferencias significativas?: {'S√ç' if p_kw < 0.05 else 'NO'}\")\n",
        "\n",
        "# Comparaciones pareadas con Mann-Whitney U (Post-hoc)\n",
        "if p_kw < 0.05:\n",
        "    print(\"\\nCOMPARACIONES PAREADAS (Mann-Whitney U):\")\n",
        "    print(\"Nota: Se aplica correcci√≥n de Bonferroni (alpha = 0.05 / 3 = 0.0167)\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    alpha_corregido = 0.05 / 3  # Correcci√≥n para 3 comparaciones\n",
        "\n",
        "    # Generamos pares\n",
        "    pares = list(combinations(orden_segmentos, 2))\n",
        "\n",
        "    print(f\"{'Comparaci√≥n':<20} | {'U Stat':<10} | {'p-value':<10} | {'Sig? (Bonferroni)'}\")\n",
        "    print(\"-\" * 75)\n",
        "\n",
        "    for seg1, seg2 in pares:\n",
        "        # alternative='two-sided' es el est√°ndar\n",
        "        u_stat, p_mw = stats.mannwhitneyu(segmentos_dict[seg1], segmentos_dict[seg2], alternative='two-sided')\n",
        "\n",
        "        significativo = \"S√ç\" if p_mw < alpha_corregido else \"NO\"\n",
        "        print(f\"{seg1} vs {seg2:<9} | {u_stat:<10.1f} | {p_mw:.4e}   | {significativo}\")\n",
        "else:\n",
        "    print(\"\\nNo se realizan pruebas post-hoc porque Kruskal-Wallis no fue significativo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0SKvaTPX56Z",
        "outputId": "cf06a4f0-5fba-4a15-fac9-88c5e72bf4c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "COMPARACI√ìN DE GASTO TOTAL ENTRE SEGMENTOS\n",
            "==================================================\n",
            "Segmento   |    Mediana |        IQR |     n\n",
            "---------------------------------------------\n",
            "Bronce     | $      120 | $      202 |   144\n",
            "Plata      | $      199 | $      317 |    93\n",
            "Oro        | $      268 | $      416 |    63\n",
            "\n",
            "PRUEBA KRUSKAL-WALLIS (Global):\n",
            "------------------------------\n",
            "Estad√≠stico H: 17.095\n",
            "Valor p: 1.9405e-04\n",
            "¬øExisten diferencias significativas?: S√ç\n",
            "\n",
            "COMPARACIONES PAREADAS (Mann-Whitney U):\n",
            "Nota: Se aplica correcci√≥n de Bonferroni (alpha = 0.05 / 3 = 0.0167)\n",
            "---------------------------------------------------------------------------\n",
            "Comparaci√≥n          | U Stat     | p-value    | Sig? (Bonferroni)\n",
            "---------------------------------------------------------------------------\n",
            "Bronce vs Plata     | 5269.0     | 5.6418e-03   | S√ç\n",
            "Bronce vs Oro       | 3032.0     | 1.4974e-04   | S√ç\n",
            "Plata vs Oro       | 2527.0     | 1.4651e-01   | NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1Ô∏è‚É£ ¬øPor qu√© las pruebas no param√©tricas son m√°s apropiadas que las param√©tricas para este dataset?\n",
        "\n",
        "Porque este dataset no cumple los supuestos que necesitan las pruebas param√©tricas.\n",
        "\n",
        "Las pruebas param√©tricas (t-test, ANOVA, Pearson) asumen:\n",
        "\n",
        "Datos aproximadamente normales\n",
        "Varianzas similares\n",
        "Relaci√≥n lineal (en correlaci√≥n)\n",
        "Sensibilidad a outliers\n",
        "\n",
        "En este dataset ocurre que:\n",
        "\n",
        "Hay distribuciones no normales (exponencial, sesgadas)\n",
        "Los grupos tienen varianzas y tama√±os distintos\n",
        "Algunas relaciones son no lineales\n",
        "La mediana es m√°s representativa que la media\n",
        "\n",
        "‚û°Ô∏è Por eso, usar pruebas param√©tricas podr√≠a dar conclusiones enga√±osas.\n",
        "\n",
        "En cambio, las pruebas no param√©tricas:\n",
        "\n",
        "No asumen normalidad\n",
        "Trabajan con rangos en vez de valores exactos\n",
        "Son m√°s robustas frente a outliers y asimetr√≠as\n",
        "\n",
        "üëâ Conclusi√≥n:\n",
        "Las pruebas no param√©tricas son m√°s apropiadas porque se adaptan mejor a la estructura real de los datos y entregan resultados m√°s confiables.\n",
        "\n",
        "2Ô∏è‚É£ ¬øC√≥mo afectan los intervalos de confianza bootstrap la interpretaci√≥n de los resultados?\n",
        "\n",
        "Los intervalos de confianza bootstrap cambian c√≥mo entendemos la incertidumbre del resultado.\n",
        "\n",
        "En m√©todos cl√°sicos:\n",
        "\n",
        "El IC depende de que los datos sean normales\n",
        "Si no lo son, el intervalo puede ser incorrecto\n",
        "\n",
        "Con bootstrap:\n",
        "\n",
        "El intervalo se construye a partir de los propios datos\n",
        "No depende de supuestos te√≥ricos\n",
        "Refleja mejor la variabilidad real del estad√≠stico\n",
        "\n",
        "En este dataset:\n",
        "\n",
        "Permite estimar IC para estad√≠sticas como la mediana\n",
        "Da una idea m√°s realista de qu√© tan preciso es el resultado\n",
        "Hace que la conclusi√≥n sea m√°s cauta y confiable\n",
        "\n",
        "üëâ Por ejemplo:\n",
        "\n",
        "Si el IC bootstrap es estrecho ‚Üí resultado estable\n",
        "Si es amplio ‚Üí alta incertidumbre, aunque el valor central parezca bueno\n",
        "\n",
        "üß† Respuesta corta\n",
        "\n",
        "Las pruebas no param√©tricas son m√°s adecuadas porque el dataset presenta distribuciones no normales, varianzas desiguales y posibles valores at√≠picos, lo que viola los supuestos de las pruebas param√©tricas.\n",
        "Los intervalos de confianza bootstrap permiten estimar la incertidumbre del estad√≠stico sin asumir una distribuci√≥n espec√≠fica, proporcionando una interpretaci√≥n m√°s robusta y realista de los resultados.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Tgfc-HL-ZDVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}